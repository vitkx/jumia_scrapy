import scrapy

# import w3lib.html

from ..items import JumiascraperItem
from bs4 import BeautifulSoup as bs, Tag
import html5lib

class JumiaphonesSpider(scrapy.Spider):
    name = "jumiaphones"
    start_urls = ["http://jumia.co.ke/mobile-phones//"]

    def parse(self, response):
        items = JumiascraperItem()

        try:
            print("\nTrying to fetch phones in our container...")
            for arts in response.xpath(
                "/html/body/div/main/div[2]/div[3]/section/div[1]"
            ):


            sec = response.xpath("//section[@class='card -fh']/div[@class='-paxs row _no-g _4cl-3cm-shs']")
            soup = bs(sec.extract_first(), "html5lib")
            articles = soup.find_all("article", {"class": "prd _fb col c-prd"})

            def parse_result_page(articles: bs) -> dict:
for i, art in enumerate(articles):
    if i < 2 :
        core = art.find("a", {"class": "core"})
        data = {}
        data["name2"] = core.find("h3", {"class": "name"})
        print(type(data["name2"]))
        isinstance(data["name2"], Tag)
        data["name"] = core.get("data-name").text()
                        data["href"] = core.get("href")
                        data["data-id"] = core.get("data-id")
                        data["brand"] = core.get("data-brand")
                        data["name2"] = core.find("h3", {"class": "name"}).get_text()
                        data["price"] = core.find("div", {"class": "prc"}).get_text()
                        data["old_price"] = core.find("div", {"class": "s-prc-w"}).find("div", {"class": "old"}).get_text()
                        data["discount"] = core.find("div", {"class": "s-prc-w"}).find("div", {"class": "bdg _dsct _sm"}).get_text()
                        data["votes"] = core.find("div", {"class": "rev"}).find(text=re.compile(r"\(*\)") )
                        data["stars"] = core.find("div", {"class": "rev"}).find("div", {"class": "stars _s"}).get_text()
                        data["official_store"] = core.find("div", {"class": "bdg _mall _xs"}).get_text()
                        data["image_url"] = core.find("div", {"class": "img-c"}).find("img", {"class": "img"}).get("data-src")
                        print(i, "    ", data["image_url"])
                        print()

                    yield data 

        # print( core.find("div", {"class": "bdg _mall _xs"}).get_text() )
        
        # print( data["votes"], data["stars"])
        # print( core.find("div", {"class": "s-prc-w"}) )
        print(data)

                            sec = response.xpath("//section[@class='card -fh']/div[@class='-paxs row _no-g _4cl-3cm-shs']/article[@class='prd _fb col c-prd']/a[@class='core']")
                            sec = response.xpath("//section[@class='card -fh']/div[@class='-paxs row _no-g _4cl-3cm-shs']/article[@class='prd _fb col c-prd']")
                            root = "//section[@class='card -fh']/div[@class='-paxs row _no-g _4cl-3cm-shs']/article[@class='prd _fb col c-prd']"
                            prefix = "/article[{3}]/a"
                #             curr = 1
                #             article = response.xpath(f"{root}/article[{curr}]/a")
                # root = "//section[@class='card -fh']/div[@class='-paxs row _no-g _4cl-3cm-shs']/article[@class='prd _fb col c-prd']"
                # curr = 2
                # prefix = f"article[{curr}]/a"
                # article = response.xpath(f"{root}/{prefix}")

                # /html/body/div[1]/main/div[2]/div[3]/section/div[1]/article[1]/a
                # /html/body/div[1]/main/div[2]/div[3]/section/div[1]/article[2]
                # /html/body/div[1]/main/div[2]/div[3]/section/div[1]/article[3]

                # def extract_element(root, index):
                #     root.xpath(f"/article[{3}]/a")

                # for i, art in enumerate(sec):
                #     if i == 1 :
                #         names = art.xpath("//a/div[@class='info']/h3[@class='name']/text()")
                #         prices = art.xpath("//a/div[@class='info']//div[@class='prc']/text()")
                #         old_prices = art.xpath("//a/div[@class='info']/div[@class='s-prc-w']/div[@class='old']/text()")
                #         discount_percents = art.xpath("//a/div[@class='info']/div[@class='s-prc-w']/div[@class='bdg _dsct _sm']/text()")
                #         for i in len(sec) :
                #             try:
                #                 data = {
                #                     "name": names[i]
                # for ii, v in enumerate(art.xpath("//a/div[@class='info']/div[@class='s-prc-w']/div[@class='old']/text()")) :
                # print(v.extract())
                # print(ii)
                # print( len(art.xpath("//a/div[@class='info']/h3[@class='name']")))
                # print( art.xpath("//a/div[@class='info']/h3[@class='name']"))

                # for ii, v in enumerate(art.xpath("//div[@class='info']/h3[@class='name']").extract()):
                #     if ii < 1:
                #         print(v)
                # print(v.xpath("//h3[@class='name']").extract_first())
                # print( len(art.xpath("//div[@class='info']")))
                #  print( art.xpath("@data-name").extract_first())
                # pass
                # [
                #     art[1].xpath("//div[@class='info']/div[@class='prc']/text()").get()
                #     for art in lan
                # ]

                # for idx, art in enumerate(arts.xpath("//article/a[@class='core']")):
                #     if idx < 4:
                #         # phone_price = art.xpath("//a[@class='core']/@data-name").extract_first()
                #         # print(art.xpath("@href").get())
                #         # print(art.xpath("@data-name").get())
                #         # print(art.xpath("@data-id").get())
                #         # print(art.xpath("@data-brand").get())
                #         # print(art.xpath("@data-category").get())
                #         # print(art.xpath("@data-dimension").get())
                #         for idx1, key in enumerate(art.xpath("//div")):
                #             if idx1 == 0:
                #                 print(key.extract())

                # phone_url = art.xpath("@href").get()
                # phone_name = art.xpath("@data-name").get()
                # phone_price = art.xpath(
                #     "//div[@class='info']/div[@class='prc']/text()"
                # ).get()
                # listing = response.xpath(
                #     "/html/body/div/main/div[2]/div[3]/section/div[1]/article/a"
                #      /html/body/div/main/div[2]/div[3]/section/div[1]/article[1]/a
                # ).getall()
                # print(len(listing))
                # phone_names = response.selector.xpath(
                #     "/html[1]/body[1]/div[1]/main[1]/div[2]/div[3]/section[1]/div[1]/article/a/div/h3[1]/text()"
                # ).getall()
                # phone_price = response.selector.css(".info .prc::text").getall()
                # price_rating = response.selector.xpath(
                #     "/html[1]/body[1]/div[1]/main[1]/div[2]/div[3]/section[1]/div[1]/article/a/div/div/div[1]/text()"
                # ).getall()
                # old_price = [k for i, k in enumerate(price_rating) if i % 2 == 0]
                # ratings = [k for i, k in enumerate(price_rating) if i % 2 != 0]

                # items["phone_names"] = phone_names

                # items["phone_price"] = phone_price
                # items["old_price"] = old_price
                # items["ratings"] = ratings
                # items["listing"] = listing

                yield items

        except Exception as err:
            print(f"\nEncounterd an exception during execution: \n{err}")
            raise err

        else:
            pass
            # for next_page in response.xpath()
